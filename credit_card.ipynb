{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bf2223",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83537288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# KERAS\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9338f6e6",
   "metadata": {},
   "source": [
    "The previous exercises made you take a closer look at all the different parts of a neural network: \n",
    "* the architecture of a sequential Dense Neural Network, \n",
    "* the compilation method\n",
    "* the fitting.\n",
    "\n",
    "Let's now work on a real-life dataset that has **a lot of data**!\n",
    "\n",
    "**The dataset: `Credit Card Transactions`**\n",
    "\n",
    "For this open challenge, you will `work with data extracted from credit card transactions`. \n",
    "\n",
    "As this is `sensitive data`, only 3 columns are known out of a total 31: the rest have been transformed to `anonymize` them (in fact, they are `PCA projections of initial data`).\n",
    "\n",
    "The 3 known columns are:\n",
    "\n",
    "* `TIME`: the time elapsed between the transaction and the first transaction in the dataset\n",
    "* `AMOUNT`: the amount of the transaction\n",
    "* `CLASS` (our target): \n",
    "    * `0 : valid transaction` \n",
    "    * `1 : fraudulent transaction`\n",
    "\n",
    "‚ùì **Question** ‚ùì Start by downloading the dataset:\n",
    "* on the Kaggle website [here](https://www.kaggle.com/mlg-ulb/creditcardfraud) \n",
    "* or from our [URL](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/creditcard.csv) \n",
    "\n",
    "Load data to create `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97480adb",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "url = 'https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/creditcard.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30db28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['Class']\n",
    "X = data.drop(columns='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d87928",
   "metadata": {},
   "source": [
    "## 1. Rebalancing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02a9b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check class balance\n",
    "pd.Series(y).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60891ef9",
   "metadata": {},
   "source": [
    "‚òùÔ∏è in this `fraud detection` challenge, **the classes are extremely imbalanced**:\n",
    "* 99.8 % of normal transactions\n",
    "* 0.2 % of fraudulent transactions\n",
    "\n",
    "**We won't be able to detect cases of fraud unless we apply some serious rebalancing strategies!**\n",
    "\n",
    "‚ùì **Question** ‚ùì\n",
    "1. **First**, create three separate splits `Train/Val/Test` from your dataset. It is extremely important to keep validation and testing sets **unbalanced** so that when you evaluate your model, it is done in true conditions, without data leakage. Keep your test set for the very last cell of this notebook!\n",
    "\n",
    "&nbsp;\n",
    "2. **Second**, rebalance your training set (and only this one). You have many choices:\n",
    "\n",
    "- Simply oversample the minority class randomly using plain Numpy functions (not the best option since you are duplicating rows and hence creating data leakage)\n",
    "- Or use <a href=\"https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\">**`Synthetic Minority Oversampling Technique - SMOTE`**</a> to generate new datapoints by weighting the existing ones\n",
    "- In addition, you can also try a <a href=\"https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\">**`RandomUnderSampler`**</a> to downsample the majority class a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b7eace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381c83e7",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "## split the data into train and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "# split the train set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                  test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c896d7b9",
   "metadata": {},
   "source": [
    "## 2. Neural Network iterations\n",
    "\n",
    "Now that you have rebalanced your classes, try to fit a neural network to optimize your test score. Feel free to use the following hints:\n",
    "\n",
    "- Normalize your inputs!\n",
    "    - Use preferably a [`Normalization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization) layer inside the model to \"pipeline\" your preprocessing within your model. \n",
    "    - Or use sklearn's [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) outside of your model, applied your `X_train` and `X_val` and `X_test`.\n",
    "- Make your model overfit, then regularize  it using:\n",
    "    - Early Stopping criteria \n",
    "    - [`Dropout`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layers\n",
    "    - or [`regularizers`](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers) layers\n",
    "- üö® Think carefully about the metrics you want to track and the loss function you want to use!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2a53c4",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "#scaling my data\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_val_norm = scaler.transform(X_val)\n",
    "X_test_norm = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9afa9613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149523, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb39035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def credit_card_model(): \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(32,activation='relu',input_dim=30))\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    model.add(layers.Dense(16, activation='relu',))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = credit_card_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "239cfa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model: \n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy','Precision']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f18a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "9331/9346 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9994 - precision: 0.8803WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
      "9346/9346 [==============================] - 3s 348us/step - loss: 0.0033 - accuracy: 0.9994 - precision: 0.8803 - val_loss: 0.0041 - val_accuracy: 0.9993 - val_precision: 0.8000\n",
      "Epoch 2/500\n",
      "9245/9346 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9994 - precision: 0.8826WARNING:tensorflow:Can save best model only with val_auc available, skipping.\n",
      "9346/9346 [==============================] - 3s 344us/step - loss: 0.0032 - accuracy: 0.9994 - precision: 0.8851 - val_loss: 0.0041 - val_accuracy: 0.9993 - val_precision: 0.8375\n",
      "Epoch 3/500\n",
      "7663/9346 [=======================>......] - ETA: 0s - loss: 0.0029 - accuracy: 0.9993 - precision: 0.8497"
     ]
    }
   ],
   "source": [
    "#fit the model \n",
    "es_cb = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "mc_cb = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_auc', mode='max')\n",
    "\n",
    "history = model.fit(X_train_norm, y_train, epochs=500, batch_size=16, validation_data=(X_val_norm, y_val), callbacks=[es_cb, mc_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb4e8197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671/2671 [==============================] - 1s 197us/step - loss: 0.0027 - accuracy: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0026805310044437647, 0.9994031190872192]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_norm,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1c7be",
   "metadata": {},
   "source": [
    "### üß™ Test your score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a7237d",
   "metadata": {},
   "source": [
    "Store below your real test performance on a (`X_test`, `y_test`) representative sample of the original unbalanced dataset into `precision` and `recall` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b15586",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2414e087",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbresult\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChallengeResult\n\u001b[1;32m      3\u001b[0m result \u001b[38;5;241m=\u001b[39m ChallengeResult(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m     precision\u001b[38;5;241m=\u001b[39m\u001b[43mprecision\u001b[49m,\n\u001b[1;32m      5\u001b[0m     recall\u001b[38;5;241m=\u001b[39mrecall,\n\u001b[1;32m      6\u001b[0m     fraud_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_test[y_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m      7\u001b[0m     non_fraud_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(y_test[y_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m result\u001b[38;5;241m.\u001b[39mwrite()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mcheck())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('solution',\n",
    "    precision=precision,\n",
    "    recall=recall,\n",
    "    fraud_number=len(y_test[y_test == 1]),\n",
    "    non_fraud_number=len(y_test[y_test == 0]),\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a42de51",
   "metadata": {},
   "source": [
    "## üèÅ Optional: Read Google's solution for this challenge\n",
    "Congratulations for finishing all challenges for this session!\n",
    "\n",
    "To conclude, take some time to read Google's own solution direcly [on Colab here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/imbalanced_data.ipynb). \n",
    "\n",
    "You will discover interesting techniques and best practices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
